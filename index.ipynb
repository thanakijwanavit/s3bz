{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# from your_lib.core import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S3Bz\n",
    "\n",
    "> save and load dictionary to s3 using bz compression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "full docs here https://thanakijwanavit.github.io/s3bz/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pip install s3bz`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a bucket and make sure that it has transfer acceleration enabled\n",
    "#### create a buket\n",
    "`aws s3 mb s3://<bucketname>`\n",
    "#### put transfer acceleration\n",
    "`aws s3api put-bucket-accelerate-configuration --bucket <bucketname> --accelerate-configuration Status=Enabled`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, import the s3 module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# import pickle\n",
    "# KEY = ''\n",
    "# PW = ''\n",
    "# keypath = '/Users/nic/.pip-tester-pybz'\n",
    "# if KEY and PW:\n",
    "#   with open (keypath, 'wb') as f:\n",
    "#     pickle.dump({\n",
    "#         'KEY': KEY,\n",
    "#         'PW': PW\n",
    "#     }, f)\n",
    "# with open(keypath, 'rb') as f:\n",
    "#   creden = pickle.load(f)\n",
    "# USER = creden['KEY']\n",
    "# PW = creden['PW']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import logging\n",
    "logging.basicConfig(level=logging.WARNING)\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "from s3bz.s3bz import S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set up dummy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "bucket = 'pybz-test'\n",
    "key = 'test.dict'\n",
    "sampleDict = {'test': 'bool'}\n",
    "USER = None\n",
    "PW = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#Dummy Data\n",
    "from random import randrange\n",
    "from dataclasses import dataclass\n",
    "from dataclasses_json import dataclass_json\n",
    "numberOfRows = 1000\n",
    "@dataclass_json\n",
    "@dataclass\n",
    "class Inventory:\n",
    "  ib_prcode:str\n",
    "  ib_brcode:str\n",
    "  ib_cf_qty:str\n",
    "  new_ib_vs_stock_cv:str\n",
    "\n",
    "sampleDict = [ Inventory.from_dict({\n",
    "    'ib_brcode' : str(randrange(1000,1030,1)),\n",
    "    'ib_prcode' : str(randrange(10000,100000,1)),\n",
    "    'ib_cf_qty' : str(randrange(-10,1000,1)),\n",
    "    'new_ib_vs_stock_cv' : str(randrange(-10,1000,1))\n",
    "  }).to_dict() for _ in range(numberOfRows)]\n",
    "# sampleLargeRandomInput[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BZ2 compression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save object using bz2 compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success\n"
     ]
    }
   ],
   "source": [
    "result = S3.save(key = key, \n",
    "       objectToSave = sampleDict,\n",
    "       bucket = bucket,\n",
    "       user=USER,\n",
    "       pw = PW,\n",
    "       accelerate = True)\n",
    "print(('failed', 'success')[result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "assert result, 'saving failed'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load object with bz2 compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ib_prcode': '23238', 'ib_brcode': '1015', 'ib_cf_qty': '703', 'new_ib_vs_stock_cv': '768'}\n"
     ]
    }
   ],
   "source": [
    "result = S3.load(key = key,\n",
    "       bucket = bucket,\n",
    "       user = USER,\n",
    "       pw = PW,\n",
    "       accelerate = True)\n",
    "print(result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "assert result == sampleDict, f'wrong result {result}, should be {sampleDict}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## other compressions\n",
    "Zl : zlib compression with json string encoding\n",
    "pklzl : zlib compression with pickle encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pybz-test\n",
      "CPU times: user 23.9 ms, sys: 559 µs, total: 24.5 ms\n",
      "Wall time: 155 ms\n",
      "CPU times: user 28.3 ms, sys: 3.04 ms, total: 31.4 ms\n",
      "Wall time: 154 ms\n",
      "CPU times: user 21.6 ms, sys: 228 µs, total: 21.9 ms\n",
      "Wall time: 151 ms\n",
      "CPU times: user 31.6 ms, sys: 0 ns, total: 31.6 ms\n",
      "Wall time: 114 ms\n"
     ]
    }
   ],
   "source": [
    "print(bucket)\n",
    "%time S3.saveZl(key,sampleDict,bucket)\n",
    "%time S3.loadZl(key,bucket)\n",
    "%time S3.savePklZl(key,sampleDict,bucket)\n",
    "%time result =S3.loadPklZl(key,bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bring your own compressor and encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31 ms, sys: 0 ns, total: 31 ms\n",
      "Wall time: 155 ms\n",
      "CPU times: user 32.5 ms, sys: 51 µs, total: 32.5 ms\n",
      "Wall time: 115 ms\n"
     ]
    }
   ],
   "source": [
    "import gzip, json\n",
    "compressor=lambda x: gzip.compress(x)\n",
    "encoder=lambda x: json.dumps(x).encode()\n",
    "decompressor=lambda x: gzip.decompress(x)\n",
    "decoder=lambda x: json.loads(x.decode())\n",
    "\n",
    "%time S3.generalSave(key, sampleDict, bucket = bucket, compressor=compressor, encoder=encoder )\n",
    "%time result = S3.generalLoad(key, bucket , decompressor=decompressor, decoder=decoder)\n",
    "assert result == sampleDict, 'not the same as sample dict'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check if an object exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exist\n"
     ]
    }
   ],
   "source": [
    "result = S3.exist('', bucket, user=USER, pw=PW, accelerate = True)\n",
    "print(('doesnt exist', 'exist')[result])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## presign download object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide\n",
    "S3.save(key, sampleDict,bucket=bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://pybz-test.s3-accelerate.amazonaws.com/test.dict?AWSAccessKeyId=AKIAVX4Z5TKDSNNNULGB&Signature=BR8Laz3uvkNKGh%2FBZ8x7IhRE3OU%3D&Expires=1616667887\n"
     ]
    }
   ],
   "source": [
    "url = S3.presign(key=key,\n",
    "              bucket=bucket,\n",
    "              expiry = 1000,\n",
    "              user=USER,\n",
    "              pw=PW)\n",
    "print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "assert url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### download using signed link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from s3bz.s3bz import Requests\n",
    "result = Requests.getContentFromUrl(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "assert result == sampleDict, 'not returning the correct object'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save without compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputPath = '/tmp/tmpFile.txt'\n",
    "key = 'tmpFile'\n",
    "downloadPath = '/tmp/downloadTmpFile.txt'\n",
    "with open(inputPath , 'w')as f:\n",
    "  f.write('hello world')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S3.saveFile(key =key ,path = inputPath,bucket = bucket)\n",
    "##test\n",
    "S3.exist(key,bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load without compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S3.loadFile(key= key , path = downloadPath, bucket = bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "##test\n",
    "with open(downloadPath, 'r') as f:\n",
    "  print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = S3.deleteFile(key, bucket)\n",
    "## test\n",
    "S3.exist(key,bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save and load pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>test</th>\n",
       "      <th>test2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  test  test2\n",
       "0           0     1      2\n",
       "1           1     2      3\n",
       "2           2     3      4\n",
       "3           3     4      5\n",
       "4           4     5      6"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### please install in pandas, \n",
    "### this is not include in the requirements to minimize the size impact\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'test':[1,2,3,4,5],'test2':[2,3,4,5,6]})\n",
    "S3.saveDataFrame(bucket,key,df)\n",
    "S3.loadDataFrame(bucket,key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# presign post with conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from s3bz.s3bz import ExtraArgs, S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'url': 'https://pybz-test.s3-accelerate.amazonaws.com/',\n",
       " 'fields': {'Content-Type': 'image/jpeg',\n",
       "  'key': 'test.dict',\n",
       "  'AWSAccessKeyId': 'AKIAVX4Z5TKDSNNNULGB',\n",
       "  'policy': 'eyJleHBpcmF0aW9uIjogIjIwMjEtMDMtMjVUMTA6MjQ6NTJaIiwgImNvbmRpdGlvbnMiOiBbeyJidWNrZXQiOiAicHliei10ZXN0In0sIHsia2V5IjogInRlc3QuZGljdCJ9XX0=',\n",
       "  'signature': 'hwC8kIjmjNPU0KT3BE54/TUQ/7w='}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket = 'pybz-test'\n",
    "key = 'test.dict'\n",
    "fields = {**ExtraArgs.jpeg}\n",
    "S3.presignUpload(bucket, key, fields=fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python38",
   "language": "python",
   "name": "python38"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
