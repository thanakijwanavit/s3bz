{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp s3bz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S3bz\n",
    "> API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.621536\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "import requests, sys\n",
    "response = requests.get('https://tenxor.sh/6pjW')\n",
    "sampleDict = response.json()\n",
    "print(sys.getsizeof(sampleDict)/1e6)\n",
    "bucket = 'pybz-test'\n",
    "key = 'test.dict'\n",
    "# sampleDict = {'test': 'bool'}\n",
    "USER = None\n",
    "PW = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from botocore.config import Config\n",
    "from nicHelper.wrappers import add_method, add_class_method, add_static_method\n",
    "from botocore.errorfactory import ClientError\n",
    "import bz2, json, boto3, logging, requests, zlib, pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class S3:\n",
    "  @staticmethod\n",
    "  def s3(region = 'ap-southeast-1', user = None, pw = None, accelerate = True, **kwargs):\n",
    "    '''\n",
    "    create and return s3 client\n",
    "    '''\n",
    "    logging.info(f'using {(\"standard\",\"accelerate\")[accelerate]} endpoint')\n",
    "    config = Config(s3={\"use_accelerate_endpoint\": accelerate,\n",
    "                        \"addressing_style\": \"virtual\"})\n",
    "    s3 = boto3.client(\n",
    "        's3',\n",
    "        aws_access_key_id= user,\n",
    "        aws_secret_access_key= pw,\n",
    "        region_name = region,\n",
    "        config = config\n",
    "      )\n",
    "    return s3\n",
    "  @classmethod\n",
    "  def saveFile(cls, key, path, bucket = '', **kwargs):\n",
    "    '''save a file to s3'''\n",
    "    s3 = cls.s3(**kwargs)\n",
    "    result = s3.upload_file(path, bucket, key)\n",
    "    return result\n",
    "  @classmethod\n",
    "  def loadFile(cls, key, path, bucket = '', useUrl = False, **kwargs):\n",
    "    '''load file from s3'''\n",
    "    if useUrl:\n",
    "      print('using url')\n",
    "      url = cls.presign(key=key, bucket=bucket, checkExist = False)\n",
    "      r = requests.get(url)\n",
    "      if r.status_code == 200:\n",
    "        print('presign success')\n",
    "        with open(path, 'wb') as f:\n",
    "          f.write(r.content)\n",
    "        return True\n",
    "      else:\n",
    "        print('presign failed')\n",
    "    s3 = cls.s3(**kwargs)\n",
    "    result = s3.download_file(bucket,key, path )\n",
    "    return result\n",
    "  @classmethod\n",
    "  def deleteFile(cls, key, bucket, **kwargs):\n",
    "    s3 = cls.s3(**kwargs)\n",
    "    result = s3.delete_object(Bucket=bucket, Key=key)\n",
    "    return result\n",
    "  \n",
    "  @classmethod\n",
    "  def save(cls,  key, objectToSave, bucket = '',**kwargs):\n",
    "    '''\n",
    "    save an object to s3\n",
    "    '''\n",
    "    s3 = cls.s3(**kwargs)\n",
    "    compressedData = bz2.compress(json.dumps(objectToSave).encode())\n",
    "    result = s3.put_object(Body=compressedData, Bucket=bucket, Key=key)\n",
    "    success = result['ResponseMetadata']['HTTPStatusCode'] ==  200\n",
    "    logging.info('data was saved to s3')\n",
    "    if not success: raise Error(success)\n",
    "    else: return True\n",
    "  @classmethod\n",
    "  def exist(cls, key, bucket, **kwargs):\n",
    "    s3 = cls.s3(**kwargs)\n",
    "    try:\n",
    "        s3.head_object(Bucket=bucket, Key=key)\n",
    "        return True\n",
    "    except ClientError:\n",
    "        # Not found\n",
    "        return False\n",
    "\n",
    "  @classmethod\n",
    "  def load(cls, key, bucket='',fileName = '/tmp/tempFile.bz', useUrl = False, **kwargs):\n",
    "#     if not cls.exist(key, bucket, **kwargs):\n",
    "#       logging.info('object doesnt exist')\n",
    "#       return {}\n",
    "#     logging.info('object exists, loading')\n",
    "    s3 = cls.s3(**kwargs)\n",
    "    try:\n",
    "      cls.loadFile(key=key, path=fileName, bucket=bucket, useUrl=useUrl)\n",
    "#       s3.download_file(bucket,key, fileName )\n",
    "    except Exception as e:\n",
    "      print(f'error downloading file {e}')\n",
    "    with open (fileName , 'rb') as f:\n",
    "      allItemsByte = f.read()\n",
    "    if not allItemsByte: raise ValueError('all data does not exist in the database')\n",
    "    allItems = json.loads(bz2.decompress(allItemsByte).decode())\n",
    "    return allItems\n",
    "\n",
    "  @classmethod\n",
    "  def presign(cls, key, expiry = 1000, bucket = '', checkExist = True,**kwargs):\n",
    "    if checkExist: \n",
    "      if not cls.exist(key,bucket=bucket,**kwargs): return 'object doesnt exist'\n",
    "    s3 = cls.s3(**kwargs)\n",
    "    result = s3.generate_presigned_url(\n",
    "        'get_object',\n",
    "          Params={'Bucket': bucket,\n",
    "                  'Key': key},\n",
    "        ExpiresIn=expiry)\n",
    "    return result\n",
    "  @classmethod\n",
    "  def loadDataFrame(cls, bucket, key,path='/tmp/tmpfile.csv',**kwargs):\n",
    "    import pandas as pd\n",
    "    cls.loadFile(key=key, path=path,bucket=bucket, **kwargs)\n",
    "    return pd.read_csv(path)\n",
    "  @classmethod\n",
    "  def saveDataFrame(cls,bucket,key,df,path='/tmp/tmpfile.csv', **kwargs):\n",
    "    df.to_csv(path)\n",
    "    return cls.saveFile(key,path,bucket=bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gzip options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@add_class_method(S3)\n",
    "def generalSave(cls, key, objectToSave, bucket = '', \n",
    "                compressor=lambda x: zlib.compress(x), \n",
    "                encoder=lambda x: json.dumps(x).encode() ,**kwargs):\n",
    "  '''save a file to s3'''\n",
    "  s3 = cls.s3(**kwargs)\n",
    "  compressedData = compressor(encoder(objectToSave))\n",
    "  result = s3.put_object(Body=compressedData, Bucket=bucket, Key=key)\n",
    "  success = result['ResponseMetadata']['HTTPStatusCode'] ==  200\n",
    "  logging.info('data was saved to s3')\n",
    "  if not success: raise Error(success)\n",
    "  else: return True\n",
    "@add_class_method(S3)\n",
    "def generalLoad(cls, key, bucket = '',fileName = '/tmp/tempFile.bz', \n",
    "                decompressor=lambda x: zlib.decompress(x), \n",
    "                decoder=lambda x: json.loads(x.decode()), useUrl=False, **kwargs):\n",
    "  '''load file from s3'''\n",
    "  ### check object exist\n",
    "#   if not cls.exist(key, bucket, **kwargs):\n",
    "#     logging.info('object doesnt exist')\n",
    "#     return {}\n",
    "#   logging.info('object exists, loading')\n",
    "  ### download file\n",
    "  try:\n",
    "    s3 = cls.s3(**kwargs)\n",
    "#     s3.download_file(bucket,key, fileName ,useUrl=useUrl)\n",
    "    cls.loadFile(key=key, path=fileName, bucket=bucket, useUrl=useUrl)\n",
    "  except Exception as e:\n",
    "    print(f'downlaod failed {e}')\n",
    "  ### extract\n",
    "  with open (fileName , 'rb') as f:\n",
    "    allItemsByte = f.read()\n",
    "  if not allItemsByte: raise ValueError('all data does not exist in the database')\n",
    "  allItems = decoder(decompressor(allItemsByte))\n",
    "  return allItems\n",
    "  \n",
    "@add_class_method(S3)\n",
    "def saveZl(cls, key, objectToSave, bucket = '', **kwargs):\n",
    "  '''save a file to s3'''\n",
    "  return cls.generalSave(key,objectToSave, bucket )\n",
    "@add_class_method(S3)\n",
    "def loadZl(cls, key, bucket = '',fileName = '/tmp/tempFile.bz', **kwargs):\n",
    "  '''load file from s3'''\n",
    "  return cls.generalLoad(key,bucket,fileName , **kwargs)\n",
    "  \n",
    "@add_class_method(S3)\n",
    "def savePklZl(cls, key, objectToSave, bucket = '', **kwargs):\n",
    "  '''save a file to s3'''\n",
    "  return cls.generalSave(key,objectToSave, bucket, \n",
    "                         compressor=lambda x: zlib.compress(x), \n",
    "                         encoder=lambda x: pickle.dumps(x))\n",
    "  \n",
    "\n",
    "@add_class_method(S3)\n",
    "def loadPklZl(cls, key, bucket = '',fileName = '/tmp/tempFile.bz', **kwargs):\n",
    "  '''load file from s3'''\n",
    "  return cls.generalLoad(key,bucket,fileName, \n",
    "                         decompressor=lambda x: zlib.decompress(x),\n",
    "                         decoder = lambda x: pickle.loads(x), **kwargs)\n",
    "\n",
    "@add_class_method(S3)\n",
    "def saveRaw(cls, key, objectToSave, bucket = '', **kwargs):\n",
    "  '''save a file to s3'''\n",
    "  return cls.generalSave(key,objectToSave, bucket, \n",
    "                         compressor=lambda x: x, \n",
    "                         encoder=lambda x: json.dumps(x).encode())\n",
    "@add_class_method(S3)\n",
    "def loadRaw(cls, key, bucket = '',fileName = '/tmp/tempFile.bz', **kwargs):\n",
    "  '''load file from s3'''\n",
    "  return cls.generalLoad(key,bucket,fileName, \n",
    "                         decompressor=lambda x: x,\n",
    "                         decoder = lambda x: json.loads(x.decode()), **kwargs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pybz-test\n",
      "CPU times: user 18.6 ms, sys: 706 µs, total: 19.3 ms\n",
      "Wall time: 71.8 ms\n",
      "using url\n",
      "presign success\n",
      "CPU times: user 21 ms, sys: 3.3 ms, total: 24.3 ms\n",
      "Wall time: 63.7 ms\n",
      "CPU times: user 17.8 ms, sys: 209 µs, total: 18 ms\n",
      "Wall time: 167 ms\n",
      "using url\n",
      "presign success\n",
      "CPU times: user 22.1 ms, sys: 0 ns, total: 22.1 ms\n",
      "Wall time: 80 ms\n",
      "CPU times: user 17.3 ms, sys: 0 ns, total: 17.3 ms\n",
      "Wall time: 75.6 ms\n",
      "using url\n",
      "presign success\n",
      "CPU times: user 24.5 ms, sys: 202 µs, total: 24.7 ms\n",
      "Wall time: 76.7 ms\n",
      "CPU times: user 14 ms, sys: 3.4 ms, total: 17.4 ms\n",
      "Wall time: 71.8 ms\n",
      "using url\n",
      "presign success\n",
      "CPU times: user 22.5 ms, sys: 276 µs, total: 22.8 ms\n",
      "Wall time: 65.5 ms\n",
      "CPU times: user 5.71 ms, sys: 0 ns, total: 5.71 ms\n",
      "Wall time: 5.52 ms\n",
      "CPU times: user 13 ms, sys: 0 ns, total: 13 ms\n",
      "Wall time: 99.9 ms\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "print(bucket)\n",
    "# sampleDict = {'hello':'world'}\n",
    "%time S3.save(key,sampleDict,bucket)\n",
    "%time S3.load(key,bucket, useUrl = True)\n",
    "%time S3.saveZl(key,sampleDict,bucket)\n",
    "%time S3.loadZl(key,bucket, useUrl = True)\n",
    "%time S3.savePklZl(key,sampleDict,bucket)\n",
    "%time r = S3.loadPklZl(key,bucket, useUrl = True)\n",
    "%time S3.saveRaw(key,sampleDict,bucket)\n",
    "%time r = S3.loadRaw(key,bucket, useUrl = True)\n",
    "%time url = S3.presign(key, bucket=bucket, checkExist=False)\n",
    "%time r = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Requests:\n",
    "    '''\n",
    "      for uploading and downloading contents from url\n",
    "    '''\n",
    "    @staticmethod\n",
    "    def getContentFromUrl( url):\n",
    "      result = requests.get(url)\n",
    "      if not result.ok:\n",
    "        print('error downloading')\n",
    "        return result.content\n",
    "      content = result.content\n",
    "      decompressedContent = bz2.decompress(content)\n",
    "      contentDict = json.loads(decompressedContent)\n",
    "      return contentDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "bucket = 'pybz-test'\n",
    "key = 'test.dict'\n",
    "sampleDict = {'test': 'bool'}\n",
    "USER = None\n",
    "PW = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>test</th>\n",
       "      <th>test2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  test  test2\n",
       "0           0     1      2\n",
       "1           1     2      3\n",
       "2           2     3      4\n",
       "3           3     4      5\n",
       "4           4     5      6"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'test':[1,2,3,4,5],'test2':[2,3,4,5,6]})\n",
    "S3.saveDataFrame(bucket,key,df)\n",
    "S3.loadDataFrame(bucket,key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build.sh: line 1: nbdev_build_lib: command not found\n",
      "build.sh: line 2: nbdev_build_docs: command not found\n",
      "build.sh: line 3: nbdev_clean_nbs: command not found\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "!bash build.sh\n",
    "# !nbdev_build_docs --mk_readme True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23.9 ms, sys: 4.01 ms, total: 27.9 ms\n",
      "Wall time: 118 ms\n",
      "CPU times: user 2.93 ms, sys: 3.89 ms, total: 6.82 ms\n",
      "Wall time: 6.84 ms\n",
      "CPU times: user 17.4 ms, sys: 0 ns, total: 17.4 ms\n",
      "Wall time: 103 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time S3.presign(key='allData', bucket = 'product-bucket-dev-manual')\n",
    "%time S3.presign(key='allData', bucket = 'product-bucket-dev-manual', checkExist=False)\n",
    "%time S3.exist(key='allData', bucket = 'product-bucket-dev-manual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.2 ms, sys: 0 ns, total: 17.2 ms\n",
      "Wall time: 55.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import boto3\n",
    "from botocore.errorfactory import ClientError\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "try:\n",
    "    s3.head_object(Bucket='product-bucket-dev-manual', Key='allData')\n",
    "except ClientError:\n",
    "    # Not found\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from botocore.exceptions import ClientError\n",
    "@add_class_method(S3)\n",
    "def createBucket(cls, bucket:str, **kwargs):\n",
    "  s3 = cls.s3(**kwargs)\n",
    "  try:\n",
    "    s3.create_bucket(\n",
    "      Bucket=bucket,\n",
    "      CreateBucketConfiguration={'LocationConstraint':'ap-southeast-1'})\n",
    "  except ClientError as e:\n",
    "    print(e)\n",
    "  response = s3.put_bucket_accelerate_configuration(\n",
    "      Bucket=bucket ,\n",
    "      AccelerateConfiguration={\n",
    "          'Status': 'Enabled'\n",
    "      }\n",
    "  )\n",
    "  return response\n",
    "@add_class_method(S3)\n",
    "def deleteBucket(cls, bucket:str, **kwargs):\n",
    "  s3 = cls.s3(**kwargs)\n",
    "  response = s3.delete_bucket(\n",
    "    Bucket=bucket)\n",
    "  return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bucket= 'tempoprary-test-bucket'\n",
    "# S3.createBucket(bucket= bucket)\n",
    "# S3.deleteBucket(bucket= bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3.deleteBucket(bucket= bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python38",
   "language": "python",
   "name": "python38"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
